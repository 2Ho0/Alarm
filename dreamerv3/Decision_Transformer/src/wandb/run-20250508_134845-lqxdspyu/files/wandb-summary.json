{"dataset/reward_over_time": {"_type": "plotly-file", "sha256": "c5c35a7b53549b6f42168ce1b1e28ef3903113399e1bff4d35d55dbacb3700bb", "size": 12095, "path": "media/plotly/dataset/reward_over_time_0_c5c35a7b53549b6f4216.plotly.json"}, "_timestamp": 1746680188.9600067, "_runtime": 463.1889247894287, "_step": 402, "dataset/base_action_frequencies": {"_type": "plotly-file", "sha256": "0b96636118d616faf60835417433aa1fe9aea2595b04afa16284ac3eb439c301", "size": 8229, "path": "media/plotly/dataset/base_action_frequencies_1_0b96636118d616faf608.plotly.json"}, "dataset/num_trajectories": 133, "train/loss": 2.152374327124562e-05, "train/MLP_loss": 1.0526667833328247, "train/MLP_accuracy": 0.5546875, "_wandb": {"runtime": 464}}